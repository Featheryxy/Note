{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = datasets.fetch_california_housing()\n",
    "housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 100), (100,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data = datasets.make_regression()\n",
    "reg_data[0].shape, reg_data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = reg_data[0]\n",
    "y = reg_data[1]\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = datasets.make_blobs(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 7.83992738,  3.58886331],\n",
       "        [ 8.08481999,  2.36710809],\n",
       "        [ 9.55094806,  5.15416718],\n",
       "        [-1.64081453, -8.75484153],\n",
       "        [ 9.71427054,  3.994066  ],\n",
       "        [ 7.23655143,  2.47441374],\n",
       "        [ 8.38469842,  6.49753421],\n",
       "        [ 7.87082158,  3.66215005],\n",
       "        [ 8.13733657,  6.24098565],\n",
       "        [ 8.33965486,  5.08795793],\n",
       "        [-0.18600449, -7.99626913],\n",
       "        [ 7.52419565,  6.10731109],\n",
       "        [-0.37247181, -5.74899364],\n",
       "        [ 7.52955118,  2.13243207],\n",
       "        [ 6.85972802,  3.29777817],\n",
       "        [ 0.40486889, -6.03232222],\n",
       "        [ 8.09137937,  7.3338288 ],\n",
       "        [-2.15046003, -7.28571227],\n",
       "        [ 9.13261531,  1.9711785 ],\n",
       "        [ 7.54812553,  5.06964533],\n",
       "        [-0.51979048, -7.65361617],\n",
       "        [ 8.63822692,  5.79252196],\n",
       "        [ 8.20219988,  6.88064422],\n",
       "        [ 9.95541626,  5.34025752],\n",
       "        [-0.85115355, -6.93749752],\n",
       "        [ 7.81522078,  5.4585609 ],\n",
       "        [ 8.42631811,  4.09414793],\n",
       "        [ 7.68843573,  2.09105053],\n",
       "        [ 7.01685558,  3.17678734],\n",
       "        [ 9.64999   ,  4.31244387],\n",
       "        [ 8.90887302,  3.86329951],\n",
       "        [ 0.95547283, -9.33775847],\n",
       "        [-2.60554087, -6.57201892],\n",
       "        [ 6.95816962,  6.42773019],\n",
       "        [ 8.50244396,  2.27007876],\n",
       "        [ 8.43127923,  3.54356702],\n",
       "        [ 8.07048028,  5.79450478],\n",
       "        [-1.71210069, -8.24583893],\n",
       "        [ 7.91628139,  2.80814337],\n",
       "        [-0.66458945, -8.730349  ],\n",
       "        [ 0.3570057 , -7.69077062],\n",
       "        [-0.27249719, -5.60746536],\n",
       "        [-0.13999915, -8.84576198],\n",
       "        [ 0.42244275, -8.44758569],\n",
       "        [ 8.46465563,  6.1919799 ],\n",
       "        [ 8.21358213,  4.52746559],\n",
       "        [ 9.56646997,  6.01666791],\n",
       "        [ 8.30408407,  7.7834886 ],\n",
       "        [ 9.11184139,  2.31341188],\n",
       "        [-2.08328934, -6.25067799],\n",
       "        [ 7.03874224,  7.69758723],\n",
       "        [ 8.68402328,  2.66782905],\n",
       "        [ 8.04001928,  3.3800152 ],\n",
       "        [ 6.39222208,  6.33728279],\n",
       "        [ 8.5990151 ,  4.11705139],\n",
       "        [-1.19639136, -8.44129912],\n",
       "        [ 9.3789566 ,  4.71831194],\n",
       "        [-0.37661532, -5.49049857],\n",
       "        [ 1.55120983, -7.24174519],\n",
       "        [-2.32469051, -8.26106937],\n",
       "        [10.10251679,  0.95169752],\n",
       "        [ 0.72836721, -7.92555966],\n",
       "        [ 8.25579269,  6.53669779],\n",
       "        [ 0.19975407, -7.18064877],\n",
       "        [ 7.7629208 ,  5.38042564],\n",
       "        [ 8.78800939,  6.30417232],\n",
       "        [ 7.92162421,  6.06847898],\n",
       "        [ 9.06761198,  4.04761067],\n",
       "        [ 9.36746721,  2.16846685],\n",
       "        [ 7.58963968,  6.35005414],\n",
       "        [ 7.42709121,  5.22845548],\n",
       "        [ 8.49930652,  2.54241672],\n",
       "        [ 8.95034626,  3.76797386],\n",
       "        [ 8.82337912,  6.40307592],\n",
       "        [ 1.2596953 , -8.21400735],\n",
       "        [ 2.5689503 , -8.55470291],\n",
       "        [ 0.95710134, -8.14682341],\n",
       "        [ 8.75351703,  6.3204675 ],\n",
       "        [-0.46695277, -6.10734595],\n",
       "        [ 1.35475434, -6.25028857],\n",
       "        [ 0.31095058, -7.6805146 ],\n",
       "        [ 8.41556306,  5.38493666],\n",
       "        [ 6.47580454,  1.79278407],\n",
       "        [ 9.42456142,  3.81544445],\n",
       "        [ 9.17820502,  5.23235061],\n",
       "        [-1.37132233, -6.34695643],\n",
       "        [-0.09462796, -6.9571216 ],\n",
       "        [-1.01291131, -7.34119715],\n",
       "        [ 7.80814314,  2.9427102 ],\n",
       "        [ 7.68872622,  8.81968143],\n",
       "        [-0.3742369 , -8.56587258],\n",
       "        [-0.031554  , -8.56969094],\n",
       "        [-1.9284892 , -8.54044265],\n",
       "        [ 0.48214053, -6.57959037],\n",
       "        [ 6.36973707,  3.72234419],\n",
       "        [ 9.5882713 ,  6.22083151],\n",
       "        [ 9.6471321 ,  1.95444745],\n",
       "        [ 7.48355691,  6.12989886],\n",
       "        [-1.33066322, -6.24584423],\n",
       "        [10.78637745,  8.50847834],\n",
       "        [ 2.3458723 , -7.26006764],\n",
       "        [ 8.35744977,  5.53891638],\n",
       "        [ 8.01030343,  7.18011743],\n",
       "        [ 0.4308238 , -6.61773337],\n",
       "        [ 7.54736079,  5.92413358],\n",
       "        [ 1.5517337 , -9.19422204],\n",
       "        [ 7.9746942 ,  5.74592571],\n",
       "        [ 8.05276221,  1.45081655],\n",
       "        [ 0.19792547, -6.21544071],\n",
       "        [ 8.47912784,  6.73142272],\n",
       "        [ 8.43487886,  2.17691527],\n",
       "        [ 9.47520784,  2.35187332],\n",
       "        [-0.27588572, -5.53063372],\n",
       "        [-0.16475496, -7.8565945 ],\n",
       "        [ 7.52838815,  4.60729364],\n",
       "        [ 8.33039272,  5.78827312],\n",
       "        [ 7.88221673,  6.12670346],\n",
       "        [ 7.24240154,  5.76263103],\n",
       "        [ 8.01625318,  3.2197531 ],\n",
       "        [ 9.97953226,  0.6048925 ],\n",
       "        [-0.67083407, -5.99153451],\n",
       "        [ 8.71478646,  2.27947067],\n",
       "        [ 1.3459433 , -8.43535698],\n",
       "        [ 9.61872592,  5.93860576],\n",
       "        [ 9.45195554,  2.14371072],\n",
       "        [ 1.7193176 , -6.63972044],\n",
       "        [ 0.68693644, -7.38984966],\n",
       "        [ 6.3935323 ,  6.74047995],\n",
       "        [ 7.26659092,  6.39923497],\n",
       "        [-1.03875405, -7.93792651],\n",
       "        [ 8.57068859,  6.07702599],\n",
       "        [ 8.60222585,  8.20024493],\n",
       "        [-0.78925837, -7.88717381],\n",
       "        [ 7.50375316,  6.41050523],\n",
       "        [ 7.4186335 ,  8.29585598],\n",
       "        [-0.90070475, -8.15344239],\n",
       "        [ 9.96674704,  2.90276333],\n",
       "        [ 9.4033235 ,  2.42507466],\n",
       "        [-0.52267516, -7.38070743],\n",
       "        [-0.39144833, -8.20848802],\n",
       "        [-0.59856277, -7.97642693],\n",
       "        [ 7.75663216,  2.8108075 ],\n",
       "        [ 7.01262396,  5.14235689],\n",
       "        [ 8.31102875,  7.97396843],\n",
       "        [ 7.19350306,  3.61858985],\n",
       "        [ 8.74119524,  4.65126299],\n",
       "        [-3.36659138, -9.24497117],\n",
       "        [ 6.91996742,  7.72995973],\n",
       "        [10.19230615,  3.02554366],\n",
       "        [ 5.35462546,  6.11928738],\n",
       "        [ 1.67078625, -8.35047218],\n",
       "        [ 9.35776663,  3.62844836],\n",
       "        [ 9.19067848,  1.50114167],\n",
       "        [ 7.34713194,  7.2023664 ],\n",
       "        [ 9.02778922,  5.31564938],\n",
       "        [ 7.72631991,  6.66898176],\n",
       "        [-0.07606764, -6.7045743 ],\n",
       "        [-0.85930842, -7.20333324],\n",
       "        [-0.11244067, -7.24728412],\n",
       "        [ 1.11627517, -8.50935983],\n",
       "        [ 6.95581856,  5.33027201],\n",
       "        [ 6.81058033,  6.92951371],\n",
       "        [ 8.34730161,  3.28342763],\n",
       "        [-1.75094504, -6.8899258 ],\n",
       "        [ 1.80698713, -8.87714947],\n",
       "        [ 8.34104949,  6.83332402],\n",
       "        [ 9.10015318,  2.94383546],\n",
       "        [ 9.86655782,  4.11340379],\n",
       "        [ 8.86808766,  2.40212316],\n",
       "        [10.26772984,  3.81674291],\n",
       "        [ 8.03703828,  8.29707041],\n",
       "        [ 6.99175769,  5.09858098],\n",
       "        [ 7.56349864,  3.23157488],\n",
       "        [-0.02830921, -9.18338524],\n",
       "        [ 8.44626179,  4.98299764],\n",
       "        [-0.29360315, -6.65610148],\n",
       "        [ 7.17837827,  2.10304285],\n",
       "        [-1.58160762, -7.20746684],\n",
       "        [ 6.38849575,  3.52141393],\n",
       "        [ 8.15366934,  1.99425415],\n",
       "        [ 8.13592242,  4.98850876],\n",
       "        [-3.54877299, -6.37300622],\n",
       "        [ 7.50919632,  9.09296929],\n",
       "        [10.22543161,  2.98716653],\n",
       "        [ 8.92916005,  6.71011629],\n",
       "        [ 9.53466559,  4.94546883],\n",
       "        [ 1.337803  , -7.05578284],\n",
       "        [ 7.1998478 ,  5.4032999 ],\n",
       "        [ 5.981795  ,  4.47151294],\n",
       "        [ 7.36312367,  5.24465881],\n",
       "        [ 7.94562279,  2.31145467],\n",
       "        [ 9.00530971,  4.64173958],\n",
       "        [ 9.68612276,  5.4694091 ],\n",
       "        [ 8.15459857,  5.13793169],\n",
       "        [ 0.85743843, -7.78666341],\n",
       "        [ 7.50055517,  2.38836895],\n",
       "        [10.08656825,  1.42453816],\n",
       "        [ 7.94755311,  6.18613003],\n",
       "        [-0.04097614, -7.07937002],\n",
       "        [ 9.71715536,  5.48075794]]),\n",
       " array([2, 2, 2, 0, 2, 2, 1, 2, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 2, 1, 0, 1,\n",
       "        1, 2, 0, 1, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0,\n",
       "        1, 2, 1, 1, 2, 0, 1, 2, 2, 1, 2, 0, 1, 0, 0, 0, 2, 0, 1, 0, 1, 1,\n",
       "        1, 2, 2, 1, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0,\n",
       "        2, 1, 0, 0, 0, 0, 2, 1, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 2, 0, 1,\n",
       "        2, 2, 0, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 1, 2, 0, 0, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 2, 2, 0, 0, 0, 2, 1, 1, 2, 2, 0, 1, 2, 1, 0, 2, 2, 1,\n",
       "        1, 1, 0, 0, 0, 0, 2, 1, 2, 0, 0, 1, 2, 2, 2, 2, 1, 1, 1, 0, 2, 0,\n",
       "        2, 0, 2, 2, 2, 0, 1, 2, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 0, 2, 2, 1,\n",
       "        0, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x9bd8940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X+QHOV95/H3V6sBj4jDgpFtWFhDEk4kWEEyW5ic6q4MthHBGDb4B/hsF+f4SkkqTmLK0UUEygafr1BOcUgu5Ew42xfnjEE24EUO2AJbVPlMnYhXrGQhG8UYLKEVZ5SIxTFao93V9/6YmaVntp+e7pnpmd7dz6tKpd2enp5nF/F8u7/P83wfc3dERERqlvS6ASIiUiwKDCIiUkeBQURE6igwiIhIHQUGERGpo8AgIiJ1OhIYzOzzZva8mT0ROXaymT1sZj+s/n1S4L3XVs/5oZld24n2iIhI6zr1xPB3wKUNxzYA33L3s4FvVb+vY2YnA58A3gxcAHwiFEBERKQ7OhIY3P3bwOGGw1cCX6h+/QVgOOata4GH3f2wu78APMzcACMiIl20NMdrv87dnwNw9+fM7LUx5wwAz0a+P1A9luiUU07xM888syONFBFZLHbs2PHP7r682Xl5BoY0LOZYbI0OM1sHrAMYHBxkdHQ0z3aJiCw4ZrYvzXl5zkr6iZmdWm3MqcDzMeccAM6IfH86cDDuYu5+h7sPufvQ8uVNA56IiLQoz8CwBajNMroWuD/mnK3AJWZ2UnXQ+ZLqMRER6ZFOTVe9C/i/wAozO2BmHwY2Am83sx8Cb69+j5kNmdlnAdz9MPBfgO9W/3yyekxERHrE5mPZ7aGhIdcYg4hINma2w92Hmp2nlc8iIlKn17OSRETqjIyNs2nrXg5OTHJaf5n1a1cwvLrpLHbpIAUGESmMkbFxrr9vN5NTMwCMT0xy/X27ARQcukipJBEpjE1b984GhZrJqRk2bd3boxYtTgoMIlIYBycmY4+PT0yyZuM2RsbGu9yixUmBQUQK47T+cvC1WlpJwSF/CgwiUhjr166gXOoLvq60Undo8FlECqM2wLxp617GA2mlULpJOkeBQUQKZXj1AMOrB1izcVtscEhKNy1U3Z7Cq1SSiBRSXFqpXOpj/doVPWpRb9Sm8I5PTOJ0Z6xFgUFECmFkbJw1G7dx1oYHWLNxGwC3XLWSgf4yBgz0l7nlqpV1d8qN71mIA9O9mMKrVJKI9FxoYdstV63k0Q0XZ3oPhBfDzcdV1aExlTzHWvTEICI918pdcdb39CIl0wmhMZU8x1oUGESk51q5K056T1yKab6uqu7FWItSSSLSc6f1lzPPQAq9p39ZKTbF1BgUaoo+/TU6hbdbKTAFBhHpufVrV8zpvJvdFYfe8/LUDJNTx+rOnZyaoc+MmZj9Z+bD9NfaFN5uUWAQkdxEB3v7l5Vwhxcnp+bc9bZyVxz3novOWc4Xt++PPX/GnXKpL1PwWay0g5uI5KJx1lCjcqlvzvTTdoUWxUFluuv6tSvm3aykTkq7g1uuTwxmtgLYHDn0S8DH3f0vI+e8BbgfeKZ66D53/2Se7RKR/MUN9kbVBn472TEnjRfUgsBiCgStyjUwuPteYBWAmfUB48BXY079P+5+eZ5tEZHuSjOo2+mB3+CAdLmkgJBBN8cY3gr8yN33dfEzRaRHQp104zntio5jnFguUeozpmZeSZGXS33cdMW5bX/OYtLNdQzXAHcFXvsNM9tlZl83s9j/gma2zsxGzWz00KFD+bVSRDqiWQntTgz8Ni5am5icAoeTlpWCZTSkua4MPpvZccBB4Fx3/0nDa78IHHP3n5nZZcBfufvZSdfT4LPI/JBmVlKrZSpGxsb52Jd3xU5BHegvB0tpLGaFGHyO+E3g8cagAODuP418/aCZ/Q8zO8Xd/7lLbRORnDQb7G2l3lH0fXFBAYq/aK3oupVKeh+BNJKZvd7MrPr1BdU2/UuX2iUiPdRqmYpmM57mw6K1Isv9icHMlgFvB34ncux3Adz9duDdwO+Z2TQwCVzj83FxhYjMSpsearVyaLPXjxydZmRsXGMLLco9MLj7EeA1Dcduj3x9G3Bb3u0Qke7Ikh5qpUZS0vtqXjgyxXWbd/LRzTtnF7YpSKSnlc8ikkmzp4HQ6uO4AeG41dGNK6LjPg9IXFXdyACHxCAxH/dqyCrt4LPKbotIamn2NMiSHhpePZC4S1vo86B+d7dmare/oT0Y5uteDXlRET0RSS1psLjWmWdNDyXNXEr6vEc3XDz7vqQaSY3iSnGk+bkWEwUGEUktzdNAXDlso3IXvmbjtsT1C1BfLTXU2Te2Y/3aFaz/yi6mjqVLjdfeX2tD2s9ZLBQYRCS1NE8D0XLY4xOTs/l9eCVFM7rvMPfuGK8boF7/lV1gzJazSHoCaHz6GF49wM1f28MLR6ZS/xw3juwOlugOfc5ioTEGEUntonOWpzo+vHqARzdczEB/mcZ7+MmpGe567Nk5qZupY15X4ygkrpTGyNh46qBQ6rPEfRuSPidO3Dai852eGEQWqDxm2TzyZHydstDxUComtGK5mYHqZjw3bdnDRzfvBOCE4/o4On2syTsjHB743nNNPyfN76vVldtFpycGkQUor1k2WRekhVIxfZZmLlE9ozKW8KXH9leK5VW9dHQm9dgCVJ5Mmj1dRAe2k9z8tT0trdwuOgUGkQWo1VITzYQ6+tDxuAqr5VIf73vzGYmVV0OfcfPX9pAhBrSkv1xKdV5S+mq+D1orMIgsQK2Wmmgm1NGHcvGhdQqfGl4553iaz047jkD1mmmuG7UEUu/dkBRkT0wZXIpKYwwiC1CrpSaaic44Sjt2kXY7zf5yqS5FFGVWuU5tXKGZ0hLjyNFpXjgyVTcrqtnn33TFuanHBpKCbAuZskJRYBBZgOLWEnRiYxxI39EniRu0LfWFe9PaWHVS8Kgpl5YwHRlHaBYUGktwpJW0zmIiw5NNESmVJLIANSs10WtxYyBTM86SQGyopYTSpHmOTqeb9lrT6tjL+rUrguU45vv6Bz0xiCxQnbizz0soDXPMK3fwcU86tem3zbQyFbaVsZfh1QOM7jvMndv3z3kqee7FSW4c2c2nhldmvm4R6IlBRLouNDhbe7JpfNIZ3XeY6zbvTFUPKWkqbOilVu/wPzW8kluvXkW5VN+VHnP44vb93Diyu6Xr9pqeGEQkV40L7S46ZzkvHZ2ec15pic0OZEefdEbGxmPvyuOUS3286/yB4Kpm98rnRNc9NI69ZF0YOLx6gI99eVfsa196bD+PPHlo3pXy1n4MIpKbuP0WQrOEosejM4SaVU7tM2PGvW618qqbHwoOUp+0rMSy45bGdtZJ7U1aDX3mhgeSfxFVrQ50d0ra/RgUGEQkN1nKYcdpNguptvlP413+ma8p8+iPDse+x4BnNr6jpfaGNhHK8jPGbVjULYXZqMfMfmxmu81sp5nN6c2t4r+b2VNm9j0ze1PebRKR7mh3Qd3E5FRw5k+tRMbI2Djr79lVV/4jFBQgeTyhWXujM5iiZUeymA+rors1+HyRu68KRKrfBM6u/lkHfKZLbRKRnHVi2qbDnOBgwPsvHJwtt51lemqoQiyka2+tY4+bclvTZzZnQDrLZ/RaEWYlXQn8vVdsB/rN7NReN0pE2tdsQZ2RrqBeLcdfm6l069WrZqeCZimTAeFKsBBf8qNRrWNPelL40S2XcctVv56pfEiRdGNWkgMPmZkDf+vudzS8PgA8G/n+QPVYXV1cM1tH5YmCwcHB/ForIh0zvHqA6768k7ihzD4zfnTLZbOpoKS7/k7m5ZNSOUmbDEFlL4eXXp7mrITB5lqga6V8SFF0IzCscfeDZvZa4GEze9Ldvx15Pe52Yc6/kGpAuQMqg8/5NFVEOu39bx6MnT76vjefAbzSgYZ2YKtNYw1JUyYjqnbH32xr0dreD7Xppv3LSvzs59NNPyu6wK7IiwyT5J5KcveD1b+fB74KXNBwygHgjMj3pwMH826XiHTHp4ZX8oELB2fvpPvM+MCFg3WrgodXDzD28Uv4y6tXza2Z1CTTdNMV51IK1dJoEF1F3bhfxfqv7JoziH3vjnHWr13BMxvfwbLjlqba9yFrRdciyvWJwcxOAJa4+79Wv74E+GTDaVuAj5jZ3cCbgRfdPXl7JRHJRR67vkElOKQpD7Fp6945KaWpGWfT1r3BdiQ9cZSWGL/wqqVMHJmq+3nWbNwWu7Voo9ospOHVA6lmE82XMYRm8k4lvQ74qlXuFJYCX3L3b5jZ7wK4++3Ag8BlwFPAEeBDObdJRGIUYZvKVveRGF49wKate+cEhqljzrLjljL28UsyXS/u3FA11T4zjrnPqzGEZnJNJbn70+5+XvXPue7+X6vHb68GBaqzkX7f3X/Z3Ve6u1auifRAXru+ZZF1h7ioLEEly5TR2rmhTYo+/d7zuPXqVQBct3knazZua3sL1V4rwnRVESmAvHZ9yyLrDnFRWYJK3OeUltic8Y3oZ4dKmQO57K/dSyqJISJAuBxEt0s4tDrOEVfnqNRnnHDcUl6cnJot4FebZXRiuYQZdeMP8MpU1bgaTHFCv7f+cokTjo+vydQraUtiqLqqiAD57vqWRatTPBvXDTROLx2fmKybNjsxOUW51MetV6+a83lZxlpCT1QTk1N1n93t8Zp2KDCICDC/F2TVRIPKmo3bmq6Kjo6h1H7uJdUnhbjz4n4XSVt8pr1G0SgwiMis+bogK07asZHa3XztCSG0A1ztenH7S6TdLyLaprymBneCAoOIpFbkzqxR2jv5PrNgMbzG68VN6b13x3iqoFC7BhRjanASBQYRSaWTnVmrAebGkd3c9dizzLjTZ8b73nxGcOFc3JhJo8b9pZPOW792BTdt2RM7pbcvJv0UugYkTw0uQmDQdFURSSXUmd20ZU+m68SVo0gzvfPGkd18cfv+2Q54xj1xX+Xh1QO86/yBulIca3755DnTTZuVsIhOSw3VSZpxj53+etKyUt1n1Tr9IkwNTqInBhFJJWn2zcjYeOo73Vbvlu967Nng8binhpGxce7dMV4XSB7f/2Ls1prXbd4Zmw6KTtVds3FbsG21Ka1pn4JCaa6i7NWgwCAiqSTl7OM69VC6qNW75VCqZsadszY8MKczThuAhlcPMLrv8JwB5Mapukntq31u2uBYlKnBIQoMIpLK+rUr+OjmnbGvNXaaSeMRae6W44JKUh4/mpKqCQWxuA7+U8MrGXrDyYl3/KF2n7SslHlcoOhTg7XyWURSW/3Jh2LXBjSujg6tBobKiuCXjk7XVVEtl/pmUzxxK5jLpT7eNHhi4l7O0eu/PH0sOKjc6kruULviUlNFlXblswafRSS1T7zz3FS1jJLSLhOTU+AEB2ZDKaAf/8tk3b4OSdcPBYV20jWhWkmtzMhas3EbZ214oLAF95RKEpHU0qZAmq0hCJXDhnBQGZ+Y5JEnD3GsjSxH2o48ND7S7gLAuBTbdZt3MrrvcKr9KrpFgUFEMknTOaZZQxAKAKGgYoTHDaLn9C8rBdNdrRTja3fxWTTIxJXbcODO7fsZesPJhUlJKZUkIh0XTbuEhKZmxpXEhpiN4BsY8P4LB1Onu0I6uS9F45qNpMHzbu570YyeGEQkF7Uni9CgbaijjquS2qwY3knLSnzinefW3XEnpbuSVl53cvFZXJAJKcriNlBgEJGctTI1M2uV1GXHLZ2zNiF0/Wapok4uPsvS2RdlcRvkGBjM7Azg74HXA8eAO9z9rxrOeQtwP/BM9dB97v7JvNokIr0R11GnrZeUpnNtdk6zPH904VsnF5+lLeRXpMVtkOM6BjM7FTjV3R83s1cDO4Bhd/9+5Jy3AH/s7pdnubbWMYjMb6H00rvOH5jdYa0WLGo7qiXpM+OYezBt1GwgvKZW2gLCTzhZCgBm+Tm7MfCcdh1D1xa4mdn9wG3u/nDk2FtQYBBZdEIL4AzmlKV41/kD3LtjPHWuvnHRWdJiu6T3w9zgAMzp6GuD3qHppkUqVV6owGBmZwLfBt7o7j+NHH8LcC9wADhIJUjElmo0s3XAOoDBwcHz9+3bl2+jRSQ3Z214IPUeBo0F6sqlJRyZOtb0PY9uuJiRsfFgGY8kJy0r8fOpY3Pu9F9VWhI73mEQu0Vo0RRm5bOZ/QKVzv+j0aBQ9TjwBnc/D/hrYCR0HXe/w92H3H1o+fLl+TVYRHJ3YrmU+tzaIjCodL4nnXB80/ccnJicTeO04oUjc1dPT07NBAfBizbdtF25BgYzK1EJCne6+32Nr7v7T939Z9WvHwRKZnZKnm0Skd4aGRvnpaPTmd4TLZKXJi10YrmUaapoJ2RJVxVdboHBzAz4HPADd/+LwDmvr56HmV1Qbc+/5NUmEem9TVv31hXQq1lWWkJyFaRXdktr5qWj0y131OVSH/0Znmiiilz/KIs81zGsAT4I7DazWpLvT4FBAHe/HXg38HtmNg1MAtf4fCz3KiKphaaWTk4dSzXuUNstLelpYGrGU223WVMb9K6NZ4zuO8wXt+9P9d6oxvLfRR9zCMktMLj7dyD5BsDdbwNuy6sNIpKfVmfbNFtA1uxOv3EwOtT1hwJIf7nE5eedmjhdtN3xgiLt39wKrXwWkczaKTTXbAFZ0pqD2nmNK6PjgknW7TajOlGeokglLrJSYBCRzFrdtxnSlciovXZiuYQZTByZCnbsSYGm1TLZoaea/nKJE45fyvjE5GyqKpSyKlKJi6wUGEQks3YLzSV12Fk681o6qzYoPeM++6TQThonLtgYcPl5p85ZyJa1SOB8oLLbIpJZ6G64m3fJ0ZLW8MqYQidWFg+vHuBd5w/UDZI6cO+O8TkzjtLu7DYfdm6r0RODiGTWyUJzrWonnZXGI08emjOwHbp+s6ecTm/+kzc9MYhIZp3a/7gdndw3Ie/rd3Lzn27QE4OItKTd/Y/b1cl9E/K+ft5BrNP0xCAi81LcFqCdTGd18vpFGJPJQoFBROalvNNZnbx+XJAx4KJzilkQtGv7MXSS9mMQkfnmxpHd3Ll9/5z9Jro5NlOYstsiIpI8y6loNPgsIpKj2iK8UA2oIg5AKzCIiOQkzX7TRRyAVipJRCQnzTYLKmrpDD0xiIjkJClN1ImaTnlRYBARyUlokdxAf5lHN1zcgxalo1SSiEhO8l6El5fcA4OZXWpme83sKTPbEPP68Wa2ufr6Y2Z2Zt5tEhHphiLUlGpFrqkkM+sD/gZ4O3AA+K6ZbXH370dO+zDwgrv/ipldA/wZcHWe7RIR6ZZe15RqRd5PDBcAT7n70+5+FLgbuLLhnCuBL1S/vgd4q5kl7hUtIiL5yTswDADPRr4/UD0We467TwMvAq/JuV0iIhKQd2CIu/NvXBWe5hzMbJ2ZjZrZ6KFDhzrSOBERmSvvwHAAOCPy/enAwdA5ZrYUOBE43Hghd7/D3YfcfWj58mJWJBQRWQjyDgzfBc42s7PM7DjgGmBLwzlbgGurX78b2ObzseSriMgCkeusJHefNrOPAFuBPuDz7r7HzD4JjLr7FuBzwP82s6eoPClck2ebREQkWe4rn939QeDBhmMfj3z9c+A9ebdDRETS0cpnERGpo8AgIiJ1FBhERKSOAoOIiNRRYBARkToKDCIiUkeBQURE6igwiIhIHQUGERGpo8AgIiJ1FBhERKSOAoOIiNRRYBARkToKDCIiUkeBQURE6igwiIhIHQUGERGpo8AgIiJ1ctna08w2Ae8EjgI/Aj7k7hMx5/0Y+FdgBph296E82iMiIunl9cTwMPBGd/914J+A6xPOvcjdVykoiIgUQy6Bwd0fcvfp6rfbgdPz+BwREem8bowx/Dbw9cBrDjxkZjvMbF0X2iIiIk20PMZgZt8EXh/z0g3ufn/1nBuAaeDOwGXWuPtBM3st8LCZPenu3w583jpgHcDg4GCrzRYRkSZaDgzu/rak183sWuBy4K3u7oFrHKz+/byZfRW4AIgNDO5+B3AHwNDQUOz1RESkfbmkkszsUuBPgCvc/UjgnBPM7NW1r4FLgCfyaI+IiKSX1xjDbcCrqaSHdprZ7QBmdpqZPVg953XAd8xsF/CPwAPu/o2c2iMiIinlso7B3X8lcPwgcFn166eB8/L4fBERaZ1WPouISB0FBhERqaPAICIidRQYRESkjgKDiIjUUWAQEZE6CgwiIlJHgUFEROooMIiISB0FBhERqaPAICIidRQYRESkjgKDiIjUUWAQEZE6CgwiIlJHgUFEROooMIiISB0FBhERqZNbYDCzm8xsvLrn804zuyxw3qVmttfMnjKzDXm1R0RE0sllz+eIW939z0Mvmlkf8DfA24EDwHfNbIu7fz/ndomISECvU0kXAE+5+9PufhS4G7iyx20SEVnU8g4MHzGz75nZ583spJjXB4BnI98fqB6bw8zWmdmomY0eOnQoj7aKiAhtBgYz+6aZPRHz50rgM8AvA6uA54BPx10i5pjHfZa73+HuQ+4+tHz58naaLSIiCdoaY3D3t6U5z8z+J/APMS8dAM6IfH86cLCdNomISHtyG3w2s1Pd/bnqt78FPBFz2neBs83sLGAcuAb4D3m1SSpGxsbZtHUvBycmObFcwgwmjkxxWn+Z9WtXMLw6NpsnIotEnrOS/puZraKSGvox8DsAZnYa8Fl3v8zdp83sI8BWoA/4vLvvybFNi97I2DjX37ebyakZACYmp2ZfG5+YZP09uwAUHEQWMXOPTekX2tDQkI+Ojva6GfPSmo3bGJ+YTDznpGUlxj5+SZdaJCLdYmY73H2o2Xm9nq4qXdYsKAC8cGSq6TkisnApMCwyfRY3EUxE5BV5r3yWHooOMtcGlmdSpA77y6WWrq1xCZGFQYFhgWocZK4NLBuBhSJVpSXGTVecm/na19+3G9CgtchCoMCwQG3aune2466ZmokPCbVgMZBw5x99QlhiNufJY3Jqhk1b9yowiCwACgxd0G7apZX3H0wxyAyVMYdPv/e8xOs1PiGE0lFpPzP0GUpNiRTDogkMvep42k273Diymzu3759N/6R9/2n95VQzkI65N21H3NNH6DNbodSUSLEsillJtY5nfGIS55WOZ2RsPPfPjutUa2mXZkbGxuuCQpb3r1+7gnKpr+lnpOnM0zwJlEt9rF+7oul5cdr5HYlI5y2KwJBHxzMyNs6ajds4a8MDrNm4LRhkQp1qms5209a9wYHiZu8fXj3ALVetZKC/jFFZtFZaUj9VNW1nHgoetamvfWazv89Wgm07vyMR6bxFkUrqdMeTJfURSum0e6ee5v3Dqwfq2tOYTrvonOVs2rqX6zbvTEyvrV+7ou7nBSj1GaUlxpEpnx1zaDUFlOZ3pDEIke5ZFIGhnc45TtITSGNnFdepZrlTj2u3Va+bVTRQhILb6L7DPPLkodgOuNYx9y8r8bOfT3Nk6ticz2hldlKz35HGIES6a1GkkuLy7e3kxLM8gTSmdAb6y9xy1cpUHVpcuw14/4WDbXeIoeB25/b9sWMxw6sHeHTDxTyz8R0sO24pU8fCqyGyPok1+x1pDEKkuxbFE0PjHW+7qYisTyCNKZ2opBRJ1nZnSbeEOu/QQHf0Os06/laexJJ+RxqDEOmuRREYILnjyaqd9FBUmhRJ2nZnTbeknc4KczvgpPe2+iSWFNQ6nQoUkWSLIpXUae2kh6I6mSLJeq2001lhbgccem9/udTS76HZdOJOpwJFJJn2Y+ihszY8EJyOapAp5RW6lgHPbHxH7Huid+lJ/wo+cOEgQ284ec6MptAgdVahPSL6zDjm3vHPE1ms0u7HsGhSSb3SSooEqLtzhvDsm9r1Qx37iQmVUqNpqlU3P1S3m1vUA997jnt3jNelqe7dMd7S00Gc0FhBdBpsK5+nKa4irVEqKUetpEgaJaWDotcPqW2/0GxBXtI2DS8cmUqdpkq78C8qzVhB1hRbL1e7i8x3uQQGM9tsZjurf35sZjsD5/3YzHZXz5v/uaEGzfL+jWMVIaE76jQ1jCaOTKXqJCda2LWtsV2tdsZpxzuyzELSFFeR1uUSGNz9andf5e6rgHuB+xJOv6h6btO813yTZppldH3AQODOOXRHnaajPK2/nKqTDH2GEd64p/E9rXbGjQEytMtclllImuIq0rpcU0lmZsB7gbvy/JyiCnVkoeNZZ9806yhr703TSSYtprvpinNj7+jHJyZZdfNDs08E7XTG0QD56fee1/YspKy/exF5Rd5jDP8O+Im7/zDwugMPmdkOM1uXdCEzW2dmo2Y2eujQoY43NA9ZO/qs02BDnTkN7+1fFn/HHz0e99m3Xr2KTw2vnH0t7slhYnKK9V/ZxcjYeLDTXWKWacyhE9OBNcVVpHUtT1c1s28Cr4956QZ3v796zmeAp9z904FrnObuB83stcDDwB+4+7ebffZ8mq6a98yYuOtD/Wrpwy+9zGRMXaP+comdn7gkdTtD00rhld3fGhf+NSqX+jo2m6kZzUoSqZf7dFV3f1uTBiwFrgLOT7jGwerfz5vZV4ELgKaBYT7p5IrrRqGg0LgCOuTF6vTUtJsBJaWEDk5Mzp5789f28EJgMLubW4Dm+bsXWcjyTCW9DXjS3Q/EvWhmJ5jZq2tfA5cAT+TYngUlNAPo5q/tSbXbGlTy7Vk2A0rKz0df+3nM00mUBoBFii3PwHANDYPOZnaamT1Y/fZ1wHfMbBfwj8AD7v6NHNuzoIRmAIXu1BvVSndn2Qxo/doVlPrmzhgqLbG6FFazwLTETOsJRAost5XP7v4fY44dBC6rfv00cF5en98rreS1W3lPu3fdDly3eWdiKYzGJ4S4VFF/ucRNV5w7+1qads24z6aqoHNVb0WkM1QSo4Na2VCm1U1oslRHDUkKCqHNgJrl7dO2a3Jqhpu/toefTx1r+rNrEFmku1QSo4NaWeCV9T21khPjE5OJq6Vr+sul2PRPkjSbAYVKX2Sp2hoqtfGxL++avZ5KW4h0n54YOijNAq/Gu9/Q3XXctRqfLpxKJx668x/oL/PohotTV1FNW9E1zVNO9Gc8cnQ69dgH1KeasmyjmoaePkSaU2DooGYbysR1qKGOPW4GUFwn6VSeCl6ePlb3WnTvhHBgAAAH6ElEQVQxVzT9E1qLUAsitXau2bgt2Hk266wb002NP3catet1srSF9o4WSUeppA5qtto21LE3JnpCK3RDneGLk1OxK4WBOemei85ZHnuN2vE0qZusnXV0JXMWtcAUp5XSFiqsJ5KOnhg6qNkezUn7LA9Unzb6zOZUYK1JeiJpdpde6+BfVYq/F3jge8/xyJOHYq/fmLppZavNWvuSNieKu16ntlEFFdYTSUtPDB0WLQb36IaL53TscWrlJMqlvrrNaRrv1LPU/8m6zuGFI1OJs4maFdxL21knVXGNu15j3aT+colXlZZw3eadqWsvNftsFdYTqafA0EVJHWqaNEeW4nKdvguOdp7tFLkL/Q7ef+Fg8Hq1YHvr1at4efoYLxyZammGkgrriaSjVFIXJaWartscu5fRnA4+bf2fULonbqC6mbjOs9U6RM3SbUnanaHUzmeLLCYKDF0W6lBbydsnCeXmb7riXKC+c3zp5engfs99Zrzr/M4Wo0sTVOKmlXZijECF9USaW7SBoWjz2Ts5yArN747TTiedcefeHeMMveHkrv1+QgPn/ctKsWMkGiMQ6axFGRiKOJ89jzRH2rvj6GenmZXUiiyBOJQyOn7pEsqlvo4FTxGJtygDQ6dX03ZKL9MczaaTtjOYnTUQJ63XuPXqVYV60hNZiBZlYNB89rBOj3VA9kCcZb2GiHTeopyuqvnsYXlM6cwaiDWtVKS3FmVgUMcT1s4ahZCsgTiPNohIeuaetkBBcQwNDfno6Ghb1yjarKSFLG7WU7nUp85epMvMbIe7DzU7r60xBjN7D3AT8KvABe4+GnnteuDDwAzwh+6+Neb9ZwF3AycDjwMfdPej7bQpLeWqu0cLy0Tml3YHn58ArgL+NnrQzH6Nyp7P5wKnAd80s3/j7o0T5f8MuNXd7zaz26kEks+02SYpIAVikfmjrTEGd/+Bu8fVLL4SuNvdX3b3Z4CngAuiJ5iZARcD91QPfQEYbqc9IiLSvrwGnweAZyPfH6gei3oNMOHu0wnniIhIlzVNJZnZN4HXx7x0g7vfH3pbzLHGUe4050TbsQ5YBzA4OBg6TURE2tQ0MLj721q47gHgjMj3pwMHG875Z6DfzJZWnxrizom24w7gDqjMSmqhTSIikkJeqaQtwDVmdnx15tHZwD9GT/DKPNlHgHdXD10LhJ5ARESkS9pax2BmvwX8NbAcmAB2uvva6ms3AL8NTAMfdfevV48/CPwndz9oZr/EK9NVx4APuPvLKT73ELAv5qVTqDyJFJ3a2Xnzpa3zpZ0wf9qqdqb3BneP3/g9Yl4ucAsxs9E0izd6Te3svPnS1vnSTpg/bVU7O29RlsQQEZEwBQYREamz0ALDHb1uQEpqZ+fNl7bOl3bC/Gmr2tlhC2qMQURE2rfQnhhERKRNCzIwmNkfm5mb2Sm9bkuImW0ysyfN7Htm9lUz6+91m6LM7FIz22tmT5nZhl63J46ZnWFmj5jZD8xsj5n9Ua/blMTM+sxszMz+oddtSWJm/WZ2T/Xf5w/M7Dd63aYQM7uu+t/+CTO7y8xe1es2AZjZ583seTN7InLsZDN72Mx+WP37pF62McmCCwxmdgbwdmB/r9vSxMPAG93914F/Aq7vcXtmmVkf8DfAbwK/BryvWjG3aKaBj7n7rwIXAr9f0HbW/BHwg143IoW/Ar7h7ucA51HQNpvZAPCHwJC7vxHoo1LVuQj+Dri04dgG4Fvufjbwrer3hbTgAgNwK/CfSai7VATu/lCkgOB2KiVBiuIC4Cl3f7q6P8bdVCrmFoq7P+fuj1e//lcqHVghCzGa2enAO4DP9rotSczsF4F/D3wOwN2PuvtEb1uVaClQNrOlwDISyup0k7t/GzjccPhKKlWkoeDVpBdUYDCzK4Bxd9/V67Zk9NvA13vdiIg01XELxczOBFYDj/W2JUF/SeWG5VivG9LELwGHgP9VTXt91sxO6HWj4rj7OPDnVLIDzwEvuvtDvW1Vote5+3NQuakBXtvj9gTNu8BgZt+s5hMb/1wJ3AB8vNdtrGnS1to5N1BJidzZu5bOkanyba+Z2S8A91IpvfLTXrenkZldDjzv7jt63ZYUlgJvAj7j7quBlyhoyqOao78SOIvKhmAnmNkHetuqhaHdHdy6LlTt1cxWUvkHsquyBxCnA4+b2QXu/v+62MRZzSrTmtm1wOXAW71Y84bTVMctBDMrUQkKd7r7fb1uT8Aa4Aozuwx4FfCLZvZFdy9iJ3YAOODutSeveyhoYADeBjzj7ocAzOw+4N8CX+xpq8J+YmanuvtzZnYq8HyvGxQy754YQtx9t7u/1t3PdPczqfwDf1OvgkIzZnYp8CfAFe5+pNftafBd4GwzO8vMjqMyoLelx22ao7oL4OeAH7j7X/S6PSHufr27n179d3kNsK2gQYHq/y/PmtmK6qG3At/vYZOS7AcuNLNl1X8Lb6WgA+VVW6hUkYaCV5Oed08MC8htwPHAw9UnnO3u/ru9bVKFu0+b2UeArVRmenze3ff0uFlx1gAfBHab2c7qsT919wd72KaF4A+AO6s3BU8DH+pxe2K5+2Nmdg/wOJV07BgFWV1sZncBbwFOMbMDwCeAjcCXzezDVILae3rXwmRa+SwiInUWTCpJREQ6Q4FBRETqKDCIiEgdBQYREamjwCAiInUUGEREpI4Cg4iI1FFgEBGROv8fS1W6qf6l9xcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(blobs[0][:, 0], blobs[0][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.59376071, 11.36363636, 11.13677866])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, :3].mean(axis=0) #前三个特征的均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.58828355, 23.29939569,  6.85357058])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, :3].std(axis=0) #前三个特征的标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X_2 = preprocessing.scale(X[:, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.34099712e-17, -6.34319123e-16, -2.68291099e-15])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.34099712e-17, -6.34319123e-16, -2.68291099e-15])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_scaler = preprocessing.StandardScaler()\n",
    "my_scaler.fit(X[:, :3])\n",
    "my_scaler.transform(X[:, :3]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.59376071, 11.36363636, 11.13677866])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, :3].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X = preprocessing.normalize(X[:, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.48255018e-04, 9.91865557e-01, 1.27289413e-01],\n",
       "       [3.86277175e-03, 0.00000000e+00, 9.99992539e-01],\n",
       "       [3.85994296e-03, 0.00000000e+00, 9.99992550e-01],\n",
       "       ...,\n",
       "       [5.09297670e-03, 0.00000000e+00, 9.99987031e-01],\n",
       "       [9.18569794e-03, 0.00000000e+00, 9.99957811e-01],\n",
       "       [3.97398371e-03, 0.00000000e+00, 9.99992104e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.59376071, 11.36363636, 11.13677866])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "X[:, :3].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.59376071, 11.36363636, 11.13677866])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "my_scaler = preprocessing.StandardScaler()\n",
    "my_scaler.fit_transform(X[:, :3])\n",
    "X[:, :3].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "new_target = preprocessing.binarize(y.reshape(-1, 1), threshold=y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = preprocessing.Binarizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin = preprocessing.Binarizer(boston.target.mean())\n",
    "new_target = bin.fit_transform(boston.target.reshape(-1, 1))\n",
    "new_target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d = np.column_stack((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-7f7cfa0a06fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "y.reshape(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
       "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
       "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
       "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
       "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
       "       [5. , 2. , 3.5, 1. , 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
       "       [6. , 2.2, 4. , 1. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
       "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
       "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
       "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
       "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
       "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [6.7, 3. , 5. , 1.7, 1. ],\n",
       "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
       "       [5.7, 2.6, 3.5, 1. , 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
       "       [6. , 3.4, 4.5, 1.6, 1. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
       "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
       "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4, 1. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5. , 2.3, 3.3, 1. , 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
       "       [6.7, 2.5, 5.8, 1.8, 2. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 2. ],\n",
       "       [5.7, 2.5, 5. , 2. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
       "       [6.4, 3.2, 5.3, 2.3, 2. ],\n",
       "       [6.5, 3. , 5.5, 1.8, 2. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
       "       [6. , 2.2, 5. , 1.5, 2. ],\n",
       "       [6.9, 3.2, 5.7, 2.3, 2. ],\n",
       "       [5.6, 2.8, 4.9, 2. , 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
       "       [6.2, 2.8, 4.8, 1.8, 2. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 2. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
       "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
       "       [6.3, 2.8, 5.1, 1.5, 2. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 2. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
       "       [6. , 3. , 4.8, 1.8, 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
       "       [6.5, 3. , 5.2, 2. , 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 2. ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.hstack((X, y.reshape(-1, 1)))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:, -1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "text_encoder = preprocessing.OneHotEncoder()\n",
    "text_encoder.fit_transform(d[:, -1:]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer()\n",
    "my_dict = [{'species': iris.target_names[i]} for i in y]\n",
    "dv.fit_transform(my_dict).toarray()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'setosa'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'versicolor'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'},\n",
       " {'species': 'virginica'}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets as d\n",
    "\n",
    "iris = d.load_iris()\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "new_target = label_binarizer.fit_transform(target)\n",
    "new_target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binarizer.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000, -1000, -1000],\n",
       "       [ 1000, -1000, -1000],\n",
       "       [ 1000, -1000, -1000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binarizer = LabelBinarizer(neg_label=-1000, pos_label=1000)\n",
    "label_binarizer.fit_transform(target)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "masking_array = np.random.binomial(1, .25, iris_X.shape).astype(bool)\n",
    "\n",
    "iris_X[masking_array] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(1, .25, iris_X.shape)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False,  True],\n",
       "       [False, False, False,  True],\n",
       "       [ True,  True, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masking_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, nan],\n",
       "       [4.9, 3. , 1.4, nan],\n",
       "       [nan, nan, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, nan],\n",
       "       [5. , 3.6, nan, 0.2]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4, -1. ],\n",
       "       [ 4.9,  3. ,  1.4, -1. ],\n",
       "       [-1. , -1. ,  1.3,  0.2]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "impute = preprocessing.Imputer()\n",
    "iris_X_prime = impute.fit_transform(iris_X)\n",
    "iris_X_prime[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 1.4],\n",
       "       [4.9, 3. , 1.4, 1.4],\n",
       "       [5.7, 3. , 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 1.4],\n",
       "       [5. , 3.6, 4.4, 0.2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute = preprocessing.Imputer(strategy='median')\n",
    "iris_X_prime = impute.fit_transform(iris_X)\n",
    "iris_X_prime[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4, -1. ],\n",
       "       [ 4.9,  3. ,  1.4, -1. ],\n",
       "       [-1. , -1. ,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5, -1. ],\n",
       "       [ 5. ,  3.6, -1. ,  0.2]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_X[np.isnan(iris_X)] = -1\n",
    "iris_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1       , 3.5       , 1.4       , 1.24144144],\n",
       "       [4.9       , 3.        , 1.4       , 1.24144144],\n",
       "       [5.80384615, 3.05333333, 1.3       , 0.2       ],\n",
       "       [4.6       , 3.1       , 1.5       , 1.24144144],\n",
       "       [5.        , 3.6       , 3.72522523, 0.2       ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute = preprocessing.Imputer(missing_values=-1)\n",
    "iris_X_prime = impute.fit_transform(iris_X)\n",
    "iris_X_prime[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Imputer in module sklearn.preprocessing.imputation:\n",
      "\n",
      "class Imputer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Imputation transformer for completing missing values.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <imputation>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  missing_values : integer or \"NaN\", optional (default=\"NaN\")\n",
      " |      The placeholder for the missing values. All occurrences of\n",
      " |      `missing_values` will be imputed. For missing values encoded as np.nan,\n",
      " |      use the string value \"NaN\".\n",
      " |  \n",
      " |  strategy : string, optional (default=\"mean\")\n",
      " |      The imputation strategy.\n",
      " |  \n",
      " |      - If \"mean\", then replace missing values using the mean along\n",
      " |        the axis.\n",
      " |      - If \"median\", then replace missing values using the median along\n",
      " |        the axis.\n",
      " |      - If \"most_frequent\", then replace missing using the most frequent\n",
      " |        value along the axis.\n",
      " |  \n",
      " |  axis : integer, optional (default=0)\n",
      " |      The axis along which to impute.\n",
      " |  \n",
      " |      - If `axis=0`, then impute along columns.\n",
      " |      - If `axis=1`, then impute along rows.\n",
      " |  \n",
      " |  verbose : integer, optional (default=0)\n",
      " |      Controls the verbosity of the imputer.\n",
      " |  \n",
      " |  copy : boolean, optional (default=True)\n",
      " |      If True, a copy of X will be created. If False, imputation will\n",
      " |      be done in-place whenever possible. Note that, in the following cases,\n",
      " |      a new copy will always be made, even if `copy=False`:\n",
      " |  \n",
      " |      - If X is not an array of floating values;\n",
      " |      - If X is sparse and `missing_values=0`;\n",
      " |      - If `axis=0` and X is encoded as a CSR matrix;\n",
      " |      - If `axis=1` and X is encoded as a CSC matrix.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  statistics_ : array of shape (n_features,)\n",
      " |      The imputation fill value for each feature if axis == 0.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  - When ``axis=0``, columns which only contained missing values at `fit`\n",
      " |    are discarded upon `transform`.\n",
      " |  - When ``axis=1``, an exception is raised if there are rows for which it is\n",
      " |    not possible to fill in the missing values (e.g., because they only\n",
      " |    contain missing values).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Imputer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Fit the imputer on X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Input data, where ``n_samples`` is the number of samples and\n",
      " |          ``n_features`` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : Imputer\n",
      " |          Returns self.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Impute all missing values in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          The input data to complete.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(preprocessing.Imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "mat = datasets.make_spd_matrix(10)\n",
    "masking_array = np.random.binomial(1, .1, mat.shape).astype(bool)\n",
    "mat[masking_array] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "impute = preprocessing.Imputer()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "mat_imputed = impute.fit_transform(mat)\n",
    "mat_imp_scaled = scaler.fit_transform(mat_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "\n",
    "pipe = pipeline.Pipeline([('impute', impute), ('scaler', scaler)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('impute', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat = pipe.fit_transform(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(new_mat, mat_imp_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68420713e+00,  3.26607315e-01, -2.15118370e-02,\n",
       "         1.00615724e-03],\n",
       "       [-2.71539062e+00, -1.69556848e-01, -2.03521425e-01,\n",
       "         9.96024240e-02],\n",
       "       [-2.88981954e+00, -1.37345610e-01,  2.47092410e-02,\n",
       "         1.93045428e-02],\n",
       "       [-2.74643720e+00, -3.11124316e-01,  3.76719753e-02,\n",
       "        -7.59552741e-02],\n",
       "       [-2.72859298e+00,  3.33924564e-01,  9.62296998e-02,\n",
       "        -6.31287327e-02]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_pca = pca.fit_transform(iris_X)\n",
    "iris_pca[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92461621, 0.05301557, 0.01718514, 0.00518309])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 解释方差比， 各个主成分能表示的变量\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=2)\n",
    "iris_X_prime = pca.fit_transform(iris_X)\n",
    "iris_X_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'PCA 2 Components')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "f = plt.figure(figsize=(5, 5))\n",
    "ax = f.add_subplot(111)\n",
    "ax.scatter(iris_X_prime[:,0], iris_X_prime[:, 1], c=iris.target)\n",
    "ax.set_title(\"PCA 2 Components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776317750248034"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 二维数据保留了多少特征\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948169145498101"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一开始设置解释变量的比例。 例如， 如果我们想介绍98%的变量\n",
    "pca = decomposition.PCA(n_components=.98)\n",
    "iris_X_prime = pca.fit_transform(iris_X)\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_X_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "base_svm = SVC()\n",
    "base_svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.make_blobs(n_features=2, centers=2)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-54-479dafedf442>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-54-479dafedf442>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    decision_boundary.append(p)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    ">>> from itertools import product\n",
    ">>> from collections import namedtuple\n",
    ">>> Point = namedtuple('Point', ['x', 'y', 'outcome'])\n",
    ">>> decision_boundary = []\n",
    ">>> xmin, xmax = np.percentile(X[:, 0], [0, 100])\n",
    ">>> ymin, ymax = np.percentile(X[:, 1], [0, 100])\n",
    ">>> for xpt, ypt in product(np.linspace(xmin-2.5, xmax+2.5, 20),np.linspace(ymin-2.5, ymax+2.5, 20)):\n",
    "        \n",
    "        p = Point(xpt, ypt, svm.predict([xpt, ypt]))\n",
    "            decision_boundary.append(p)\n",
    "            \n",
    ">>> import matplotlib.pyplot as plt\n",
    ">>> f, ax = plt.subplots(figsize=(7, 5))\n",
    ">>> import numpy as np\n",
    ">>> colors = np.array(['r', 'b'])\n",
    ">>> for xpt, ypt, pt in decision_boundary:\n",
    "        ax.scatter(xpt, ypt, color=colors[pt[0]], alpha=.15)\n",
    "        ax.scatter(X[:, 0], X[:, 1], color=colors[y], s=30)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_title(\"A well separated dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "holdout = 200\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(1000, shuffle=True)\n",
    "X_h, y_h = X[:holdout], y[:holdout]\n",
    "X_t, y_t = X[holdout:], y[holdout:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cross_validation.KFold(n=800, n_folds=4, shuffle=False, random_state=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "kfold = KFold(len(y_t), n_folds=4)\n",
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, N_train: 600, N_test: 200\n",
      "Fold: 1, N_train: 600, N_test: 200\n",
      "Fold: 2, N_train: 600, N_test: 200\n",
      "Fold: 3, N_train: 600, N_test: 200\n"
     ]
    }
   ],
   "source": [
    "output_string = \"Fold: {}, N_train: {}, N_test: {}\"\n",
    "for i, (train, test) in enumerate(kfold):\n",
    "    print(output_string.format(i, len(y_t[train]), len(y_t[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(1000, n_features=5)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st \n",
    "\n",
    "random_search_params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': st.randint(1, 4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [1, 2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "gs = GridSearchCV(lr, grid_search_params)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.93900, std: 0.00518, params: {'C': 1, 'penalty': 'l1'},\n",
       " mean: 0.94000, std: 0.00497, params: {'C': 1, 'penalty': 'l2'},\n",
       " mean: 0.93900, std: 0.00623, params: {'C': 2, 'penalty': 'l1'},\n",
       " mean: 0.93900, std: 0.00518, params: {'C': 2, 'penalty': 'l2'},\n",
       " mean: 0.93900, std: 0.00623, params: {'C': 3, 'penalty': 'l1'},\n",
       " mean: 0.93800, std: 0.00624, params: {'C': 3, 'penalty': 'l2'},\n",
       " mean: 0.93900, std: 0.00623, params: {'C': 4, 'penalty': 'l1'},\n",
       " mean: 0.93800, std: 0.00624, params: {'C': 4, 'penalty': 'l2'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, tree\n",
    "\n",
    "X, y = datasets.make_classification()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DecisionTreeClassifier in module sklearn.tree.tree object:\n",
      "\n",
      "class DecisionTreeClassifier(BaseDecisionTree, sklearn.base.ClassifierMixin)\n",
      " |  A decision tree classifier.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |  \n",
      " |  splitter : string, optional (default=\"best\")\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a percentage and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a percentage and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |          - If int, then consider `max_features` features at each split.\n",
      " |          - If float, then `max_features` is a percentage and\n",
      " |            `int(max_features * n_features)` features are considered at each\n",
      " |            split.\n",
      " |          - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |          - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float,\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\" or None, default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  presort : bool, optional (default=False)\n",
      " |      Whether to presort the data to speed up the finding of best splits in\n",
      " |      fitting. For the default settings of a decision tree on large\n",
      " |      datasets, setting this to true may slow down the training process.\n",
      " |      When using either a smaller dataset or a restricted depth, this may\n",
      " |      speed up the training.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem),\n",
      " |      or a list of arrays of class labels (multi-output problem).\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances. The higher, the more important the\n",
      " |      feature. The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance [4]_.\n",
      " |  \n",
      " |  max_features_ : int,\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (for single output problems),\n",
      " |      or a list containing the number of classes for each\n",
      " |      output (for multi-output problems).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree object\n",
      " |      The underlying Tree object.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
      " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
      " |  >>> iris = load_iris()\n",
      " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      " |  ...                             # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeClassifier\n",
      " |      BaseDecisionTree\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      " |      Build a decision tree classifier from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : array-like, shape = [n_samples, n_features], optional\n",
      " |          The indexes of the sorted training input samples. If many tree\n",
      " |          are grown on the same dataset, this allows the ordering to be\n",
      " |          cached between trees. If None, the data will be sorted here.\n",
      " |          Don't use this parameter unless you know what to do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities of the input samples X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X, check_input=True)\n",
      " |      Predict class probabilities of the input samples X.\n",
      " |      \n",
      " |      The predicted class probability is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool\n",
      " |          Run check_array on X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Returns the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples,]\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dtree.clf']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(dt, 'dtree.clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
